{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients = []\n",
    "with open('data/ingredients/all_ingredients.txt') as f:\n",
    "    for line in f:\n",
    "        ingredient = line.strip()\n",
    "        ingredients.append(ingredient)\n",
    "ingredients = sorted(ingredients, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high altitude adjustment for deep fat frying',\n",
       " \"mrs dash's fiesta lime salt-free seasoning\",\n",
       " 'high altitude adjustment for cookie',\n",
       " 'trappist or monastery-style cheese',\n",
       " 'high altitude baking quick bread',\n",
       " \"i can't believe it's not butter\",\n",
       " 'meat: safe cooking temperature',\n",
       " 'african birdseye chile pepper',\n",
       " 'heirloom weight & measurement',\n",
       " 'trompette de la mort mushroom']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "techniques = []\n",
    "with open('data/techniques/all_techniques.txt') as f:\n",
    "    for line in f:\n",
    "        technique = line.strip()\n",
    "        techniques.append(technique)\n",
    "techniques = sorted(techniques, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thermal immersion circulator',\n",
       " 'extreme-heat stir-fry',\n",
       " 'flash pasteurization',\n",
       " 'amylolytic process',\n",
       " 'biomass briquettes',\n",
       " 'coagulated protein',\n",
       " 'high heat stir fry',\n",
       " 'mongolian barbecue',\n",
       " 'culinary triangle',\n",
       " 'food preservation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singularize(word):\n",
    "    if word == 'cookies':\n",
    "        result = 'cookie'\n",
    "    elif word == 'mrs':\n",
    "        result = 'mrs'\n",
    "    elif word == 'ras':\n",
    "        result = 'ras'\n",
    "    elif word == 'somen':\n",
    "        result = 'somen'\n",
    "    elif word == 'cos':\n",
    "        result = 'cos'\n",
    "    elif word == 'monks':\n",
    "        result = \"monk's\"\n",
    "    elif word == 'webbs':\n",
    "        result = \"webb's\"\n",
    "    else:\n",
    "        result = WordNetLemmatizer().lemmatize(word.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inf_ing(v_ing):\n",
    "    inf = v_ing\n",
    "    if v_ing == 'de-seeding':\n",
    "        inf = 'de-seed'\n",
    "    elif v_ing == 'de-boning':\n",
    "        inf = 'de-bone'\n",
    "    elif v_ing == 'de-bearding':\n",
    "        inf = 'de-beard'\n",
    "    elif v_ing == 'gutting':\n",
    "        inf = 'gut'\n",
    "    elif v_ing == 'de-glazing':\n",
    "        inf = 'de-glaze'\n",
    "    elif v_ing == 'sautéing':\n",
    "        inf = 'sauté'\n",
    "    elif v_ing == 'degorging':\n",
    "        inf = 'degorge'\n",
    "    elif v_ing == 'stir-frying':\n",
    "        inf = 'stir-fry'\n",
    "    elif v_ing == 'broasting':\n",
    "        inf = 'broast'\n",
    "    elif v_ing == 'juicing':\n",
    "        inf = 'juice'\n",
    "    elif v_ing == 'parbaking':\n",
    "        inf = 'parbake'\n",
    "    elif v_ing == 'charbroiling':\n",
    "        inf = 'charbroil'\n",
    "    elif v_ing == 'crinkle-cutting':\n",
    "        inf = 'crinkle-cut'\n",
    "    elif v_ing == 'cheesemaking':\n",
    "        inf = 'cheesemake'\n",
    "    elif v_ing == 'swissing':\n",
    "        inf = 'swiss'\n",
    "    elif v_ing == 'flash-frying':\n",
    "        inf = 'flash-fry'\n",
    "    elif v_ing == 'flashbaking':\n",
    "        inf = 'flashbake'\n",
    "    else:\n",
    "        inf = WordNetLemmatizer().lemmatize(v_ing.lower(), 'v')\n",
    "    return inf\n",
    "\n",
    "def infinitive(words):\n",
    "    aux = []\n",
    "    word_list = words.split()\n",
    "    for word in word_list:\n",
    "        if word != 'cook' and word != 'cooking':\n",
    "            if word.endswith('ing'):\n",
    "                inf = inf_ing(word.lower())\n",
    "                aux.append(inf)\n",
    "#                 if inf == word:\n",
    "#                     print('NO INFINITIVE FOR', word)\n",
    "            else:\n",
    "                aux.append(word.lower())\n",
    "    result = ' '.join(aux)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load ingr_id_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 itemprop=\"name\">\n",
       "        Corn Pudding\n",
       "       </h1>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div.title-source h1[itemprop=name]')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5001', 'Southwestern Corn Bread Stuffing']\n",
      "['5002', \"Frances Oliver's Coconut Pie\"]\n",
      "['5003', 'Mirabelle Ginger Tart']\n",
      "['5004', 'Root Vegetable and Squash Purée']\n",
      "['5005', 'Corn Pudding']\n"
     ]
    }
   ],
   "source": [
    "with open('data/ingredients/epicurious_ingr_ids.csv', 'w') as f1,\\\n",
    "     open('data/techniques/epicurious_techniques.csv', 'w') as f2,\\\n",
    "     open('data/epicurious_ingredient_technique_log.txt', 'w') as log:\n",
    "    writer1 = csv.writer(\n",
    "        f1,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "    writer2 = csv.writer(\n",
    "        f2,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "    writer3 = csv.writer(\n",
    "        log,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "#     path = '/media/antonio/WD1T/datasets allrecipes and epicurious/epicurious/'\n",
    "    path = 'data/epicurious/'\n",
    "    count = 0\n",
    "    for folder_number in sorted(map(int, os.listdir(path))):\n",
    "        folder_name = str(folder_number)\n",
    "        folder_path = path + folder_name\n",
    "        for file_number in sorted(map(lambda x: int(x[:-5]), os.listdir(folder_path))):\n",
    "            file_name = str(file_number) + '.html'\n",
    "            file_path = folder_path + '/' + file_name\n",
    "            with open(file_path) as f:\n",
    "                soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "                recipe_info = soup.find('recipe-signup')\n",
    "                recipe_id = str(file_number)\n",
    "                recipe_title = soup.select('div.title-source h1[itemprop=name]')[0].string.strip()\n",
    "                info_row = [recipe_id, recipe_title]\n",
    "                print(info_row)\n",
    "#                 ingredient_ids = set()\n",
    "#                 ingredient_amounts = soup.select('section.recipe-ingredients span[itemprop=ingredients]')\n",
    "#                 for ingredient_amount in ingredient_amounts:\n",
    "#                     ingredient_id = ingredient_amount['data-id']\n",
    "#                     content = ingredient_amount.text.strip()\n",
    "#                     if content:\n",
    "#                         tokens = nltk.word_tokenize(content)\n",
    "#                         singularized = ' '.join(map(singularize, tokens))\n",
    "#                         found_ingr = False\n",
    "#                         for ingredient in ingredients:\n",
    "#                             if ingredient in singularized:\n",
    "#                                 found_ingr = True\n",
    "#                                 ingredient_ids.add(ingredient_id)\n",
    "#                                 if ingr_id_graph.add_edge(ingredient_id, ingredient):\n",
    "#                                     ingr_id_graph[ingredient_id][ingredient]['weight'] += 1\n",
    "#                                 else:\n",
    "#                                     ingr_id_graph.add_edge(ingredient_id, ingredient, weight=1)\n",
    "#                         if not found_ingr:\n",
    "#                             writer3.writerow(['INGREDIENT', file_path, singularized])\n",
    "#                 ingredient_row = info_row + list(ingredient_ids)\n",
    "#                 writer1.writerow(ingredient_row)\n",
    "                \n",
    "#                 technique_names = set()\n",
    "#                 instructions = soup.select('section.recipe-directions span.recipe-directions__list--item')\n",
    "#                 for instruction in instructions:\n",
    "#                     content = instruction.text.strip()\n",
    "#                     if content:\n",
    "#                         tokens = nltk.word_tokenize(content)\n",
    "#                         infinitived = ' '.join(map(infinitive, tokens))\n",
    "#                         found_tech = False\n",
    "#                         for technique in techniques:\n",
    "#                             if technique in infinitived:\n",
    "#                                 found_tech = True\n",
    "#                                 technique_names.add(technique)\n",
    "#                         if not found_tech:\n",
    "#                             writer3.writerow(['TECHNIQUE', file_path, infinitived])\n",
    "#                 technique_row = info_row + list(technique_names)\n",
    "#                 writer2.writerow(technique_row)\n",
    "                \n",
    "#                 count += 1\n",
    "#                 if count % 10000 == 0:\n",
    "#                     print(count, 'recipes processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredient_amount.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(ingr_id_graph, 'data/ingredients/ingr_id_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('data/allrecipes/6000/6903.html') as f:\n",
    "#     soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#     info = soup.find('recipe-signup')\n",
    "#     print(info['data-id'])\n",
    "#     print(info['data-title'])\n",
    "#     qq=info['data-title']\n",
    "#     info_row = [info['data-id'], info['data-title']]\n",
    "#     technique_names = []\n",
    "#     instructions = soup.select('section.recipe-directions span.recipe-directions__list--item')\n",
    "#     for instruction in instructions:\n",
    "#         infinitived = ' '.join(map(infinitive, instruction.string.strip().split()))\n",
    "#         for technique in techniques:\n",
    "#             if technique in infinitived:\n",
    "#                 technique_names.append(technique)\n",
    "#     technique_row = info_row + technique_names\n",
    "#     print(technique_row)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# las tecnicas no tienen pq ser solo verbos - pueden ser sustantivos, por ejemplo, bbq, fondue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for folder_name in os.listdir('data/allrecipes/'):\n",
    "#     folder_path = 'data/allrecipes/' + folder_name\n",
    "#     for file_name in os.listdir(folder_path):\n",
    "#         file_path = folder_path + '/' + file_name\n",
    "#         with open(file_path) as f:\n",
    "#             soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#             info = soup.find('recipe-signup')\n",
    "#             print(info['data-id'])\n",
    "#             print(info['data-title'])\n",
    "#             ingredients = soup.select('span[itemprop=ingredients]')\n",
    "#             for ingredient in ingredients:\n",
    "#                 print(ingredient.string.strip())\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
