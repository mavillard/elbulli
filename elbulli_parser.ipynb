{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "# client.drop_database('recipes')\n",
    "db = client.recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spanish_stopwords = set()\n",
    "with open('data/spanish_stopwords.txt') as f:\n",
    "    for line in f:\n",
    "        word = line.strip()\n",
    "        spanish_stopwords.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sublist(a, b):\n",
    "    res = False\n",
    "    for i in range(len(b)-len(a)+1):\n",
    "        if b[i:i+len(a)] == a:\n",
    "            res = True\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients_graph = nx.read_gexf('data/spanish_ingredients_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredients = ingredients_graph.nodes()\n",
    "ingredients.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "ingredients = [i for i in ingredients if i not in spanish_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['espuma fría de whisky sour de fruta de la pasión',\n",
       " 'nube de metil de puré de fruta de la pasión',\n",
       " 'nubes de metiles de purés de frutas de las pasiones',\n",
       " 'espumas frías de whiskyes soures de frutas de las pasiones',\n",
       " 'salsa de jugo de pollo al aceite de ajo',\n",
       " 'polvos de gelatinas frías de zumos de kumquates liofilizadas',\n",
       " 'agua de la cocción de los pies de cerdo',\n",
       " 'agu de la cocción de el pie de cerdo',\n",
       " 'polvo de gelatina fría de zumo de kumquat liofilizada',\n",
       " 'aceite de atún en conserva de aceite de oliva']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['karelas',\n",
       " 'crackeres',\n",
       " 'raya',\n",
       " 'emperador',\n",
       " 'soba',\n",
       " 'ananás',\n",
       " 'kobe',\n",
       " 'peras',\n",
       " 'tahinas',\n",
       " 'jazmines']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques_graph = nx.read_gexf('data/spanish_techniques_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques = techniques_graph.nodes()\n",
    "techniques.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "techniques = [t for t in techniques if t not in spanish_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hielo y salando para enfriando',\n",
       " 'cocinando en a la cazuela',\n",
       " 'hielo y salado para enfriado',\n",
       " 'cocinar en a la cazuela',\n",
       " 'cocinado en a la cazuela',\n",
       " 'cocina de retención del calor',\n",
       " 'cocinando de retención del calorizando',\n",
       " 'cocinado de retención del calorizado',\n",
       " 'cocinar de retención del calorizar',\n",
       " 'hielo y salar para enfriar']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ganshao',\n",
       " 'marinado',\n",
       " 'marcado',\n",
       " 'sofrenar',\n",
       " 'rouelle',\n",
       " 'mirepoix',\n",
       " 'itamemono',\n",
       " 'sifón',\n",
       " 'dentado',\n",
       " 'rotando']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# count = 0\n",
    "# rows = []\n",
    "\n",
    "# path = 'data/recipes/elbulli/'\n",
    "# for folder in os.listdir(path):\n",
    "#     for filename_number in sorted(map(lambda x: int(x[:-4]), os.listdir(path + folder))):\n",
    "#         filename = str(filename_number) + '.dat'\n",
    "#         with open(path + folder + '/' + filename) as f:\n",
    "#             row = {\n",
    "#                 '_id': '',\n",
    "#                 'title': '',\n",
    "#                 'year': 0,\n",
    "#                 'ingredients': set(),\n",
    "#                 'techniques': set(),\n",
    "#             }\n",
    "#             i_text = ''\n",
    "#             t_text = ''\n",
    "#             for line in f:\n",
    "#                 line = line.strip()\n",
    "#                 if line.startswith('num'):\n",
    "#                     row['_id'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&titol='):\n",
    "#                     row['title'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&any'):\n",
    "#                     row['year'] = int(line.split('=')[1])\n",
    "#                 elif line.startswith('&ingredientselaboracio'):\n",
    "#                     equals_index = line.index('=')\n",
    "#                     i_text += line[equals_index + 1:].lower() + ' - '\n",
    "#                 elif line.startswith('&descripcioelaboracio') or \\\n",
    "#                      line.startswith('&acabatipresentacio') or \\\n",
    "#                      line.startswith('&titolelaboracio'):\n",
    "#                     equals_index = line.index('=')\n",
    "#                     t_text += line[equals_index + 1:].lower() + ' - '\n",
    "#             i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             for ingr in ingredients:\n",
    "#                 ingr_tokens = nltk.word_tokenize(ingr)\n",
    "#                 if (sublist(ingr_tokens, i_text_tokens)):\n",
    "#                     row['ingredients'].add(ingr)\n",
    "#                     i_text = i_text.replace(ingr, '')\n",
    "#                     i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             row['ingredients'] = list(row['ingredients'])\n",
    "#             t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             for tech in techniques:\n",
    "#                 tech_tokens = nltk.word_tokenize(tech)\n",
    "#                 if (sublist(tech_tokens, t_text_tokens)):\n",
    "#                     row['techniques'].add(tech)\n",
    "#                     t_text = t_text.replace(tech, '')\n",
    "#                     t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             row['techniques'] = list(row['techniques'])\n",
    "#             rows.append(row)\n",
    "#             for ingr in row['ingredients']:\n",
    "#                 ingredients_graph.node[ingr]['count'] += 1\n",
    "#             for tech in row['techniques']:\n",
    "#                 techniques_graph.node[tech]['count'] += 1\n",
    "            \n",
    "#             count += 1\n",
    "#             if count % 100 == 0:\n",
    "#                 db.elbulli_aux.insert_many(rows)\n",
    "#                 rows = []\n",
    "#                 print(count, 'rows inserted')\n",
    "# db.elbulli_aux.insert_many(rows)\n",
    "# rows = []\n",
    "# print(count, 'rows inserted')\n",
    "\n",
    "# # CPU times: user 1h 26min 4s, sys: 796 ms, total: 1h 26min 4s\n",
    "# # Wall time: 1h 26min 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nx.write_gexf(ingredients_graph, 'data/spanish_ingredients_lexicon_6.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nx.write_gexf(techniques_graph, 'data/spanish_techniques_lexicon_6.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients_graph = nx.read_gexf('data/spanish_ingredients_lexicon_6.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques_graph = nx.read_gexf('data/spanish_techniques_lexicon_6.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repr_ingredients_dict = {}\n",
    "\n",
    "for syns in nx.connected_components(ingredients_graph):\n",
    "    max_ingr = ''\n",
    "    max_count = 0\n",
    "    for ingr in syns:\n",
    "        dat = ingredients_graph.node[ingr]\n",
    "        if dat['count'] > max_count:\n",
    "            max_ingr = ingr\n",
    "            max_count = dat['count']\n",
    "    if max_ingr:\n",
    "        for ingr in syns:\n",
    "            dat = ingredients_graph.node[ingr]\n",
    "            if dat['count'] > 0:\n",
    "                repr_ingredients_dict[ingr] = max_ingr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aceite de oliva'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr_ingredients_dict['aceite de olivas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1609"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repr_ingredients_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repr_techniques_dict = {}\n",
    "\n",
    "for syns in nx.connected_components(techniques_graph):\n",
    "    max_tech = ''\n",
    "    max_count = 0\n",
    "    for tech in syns:\n",
    "        dat = techniques_graph.node[tech]\n",
    "        if dat['count'] > max_count:\n",
    "            max_tech = tech\n",
    "            max_count = dat['count']\n",
    "    if max_tech:\n",
    "        for tech in syns:\n",
    "            dat = techniques_graph.node[tech]\n",
    "            if dat['count'] > 0:\n",
    "                repr_techniques_dict[tech] = max_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repr_techniques_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horno'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr_techniques_dict['al horno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(repr_ingredients_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(repr_techniques_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rows inserted\n",
      "200 rows inserted\n",
      "300 rows inserted\n",
      "400 rows inserted\n",
      "500 rows inserted\n",
      "600 rows inserted\n",
      "700 rows inserted\n",
      "800 rows inserted\n",
      "900 rows inserted\n",
      "1000 rows inserted\n",
      "1100 rows inserted\n",
      "1200 rows inserted\n",
      "1214 rows inserted\n"
     ]
    }
   ],
   "source": [
    "db.drop_collection('elbulli')\n",
    "\n",
    "count = 0\n",
    "rows = []\n",
    "\n",
    "for row in db.elbulli_aux.find():\n",
    "    repr_ingredients = set()\n",
    "    for ingr in row['ingredients']:\n",
    "        r = repr_ingredients_dict[ingr]\n",
    "        repr_ingredients.add(r)\n",
    "    row['ingredients'] = sorted(repr_ingredients)\n",
    "    repr_techniques = set()\n",
    "    for tech in row['techniques']:\n",
    "        r = repr_techniques_dict[tech]\n",
    "        repr_techniques.add(r)\n",
    "    row['techniques'] = sorted(repr_techniques)\n",
    "    rows.append(row)\n",
    "    \n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        db.elbulli.insert_many(rows)\n",
    "        rows = []\n",
    "        print(count, 'rows inserted')\n",
    "db.elbulli.insert_many(rows)\n",
    "rows = []\n",
    "print(count, 'rows inserted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
