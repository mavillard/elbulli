{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inf_ing(v_ing):\n",
    "    inf = v_ing\n",
    "    if v_ing == 'broasting':\n",
    "        inf = 'broast'\n",
    "    elif v_ing == 'juicing':\n",
    "        inf = 'juice'\n",
    "    elif v_ing == 'parbaking':\n",
    "        inf = 'parbake'\n",
    "    elif v_ing == 'sautéing':\n",
    "        inf = 'sauté'\n",
    "    elif v_ing == 'charbroiling':\n",
    "        inf = 'charbroil'\n",
    "    elif v_ing == 'crinkle-cutting':\n",
    "        inf = 'crinkle-cut'\n",
    "    elif v_ing == 'cheesemaking':\n",
    "        inf = 'cheesemake'\n",
    "    elif v_ing == 'swissing':\n",
    "        inf = 'swiss'\n",
    "    elif v_ing == 'flash-frying':\n",
    "        inf = 'flash-fry'\n",
    "    elif v_ing == 'flashbaking':\n",
    "        inf = 'flashbake'\n",
    "    else:\n",
    "        inf = WordNetLemmatizer().lemmatize(v_ing.lower(), 'v')\n",
    "    return inf\n",
    "\n",
    "def infinitive(words):\n",
    "    aux = []\n",
    "    word_list = words.split()\n",
    "    for word in word_list:\n",
    "        if word != 'cook' and word != 'cooking':\n",
    "            if word.endswith('ing'):\n",
    "                inf = inf_ing(word.lower())\n",
    "                aux.append(inf)\n",
    "                if inf == word:\n",
    "                    print('NO INFINITIVE FOR', word)\n",
    "            else:\n",
    "                aux.append(word.lower())\n",
    "    result = ' '.join(aux)\n",
    "    return result\n",
    "\n",
    "def trim(s):\n",
    "    return ' '.join(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "techniques = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_1(l):\n",
    "    r = []\n",
    "    for e in l:\n",
    "        if e not in [\n",
    "            'Template:Cooking techniques',\n",
    "            'List of cooking techniques',\n",
    "            'List of twice-baked foods',\n",
    "        ]:\n",
    "            x = e.strip().lower().replace('_', ' ')\n",
    "            x = x.split(' (')[0]\n",
    "            x = infinitive(x)\n",
    "            r.append(x)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/techniques/wikipedia_category_cooking_techniques.html') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    elems = soup.select('div#mw-pages div.mw-category-group ul li a')\n",
    "    techs = map(lambda x: trim(x['title']), elems)\n",
    "    clean_techs = clean_1(techs)\n",
    "    techniques = techniques.union(clean_techs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_4(l):\n",
    "    r = []\n",
    "    for e in l:\n",
    "        if e not in [\n",
    "            'Chinese cooking techniques',\n",
    "            'Manifold Destiny',\n",
    "            'Meat cooking techniques',\n",
    "            'Vietnamese cooking techniques',\n",
    "        ]:\n",
    "            x = e.strip().lower().replace('_', ' ')\n",
    "            x = x.split(' (')[0]\n",
    "            x = infinitive(x)\n",
    "            r.append(x)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/techniques/wikipedia_list_cooking_techniques.html') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    elems = soup.select('div#bodyContent h3 ~ ul:nth-of-type(1) li > a:nth-of-type(1)')\n",
    "    techs = map(lambda x: trim(x.string), elems)\n",
    "    clean_techs = clean_4(techs)\n",
    "    techniques = techniques.union(clean_techs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(techniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/techniques/wikipedia_techniques.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(techniques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
