{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "# client.drop_database('recipes')\n",
    "db = client.recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spanish_stopwords = set()\n",
    "with open('data/spanish_stopwords.txt') as f:\n",
    "    for line in f:\n",
    "        word = line.strip()\n",
    "        spanish_stopwords.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sublist(a, b):\n",
    "    res = False\n",
    "    for i in range(len(b)-len(a)+1):\n",
    "        if b[i:i+len(a)] == a:\n",
    "            res = True\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients_graph = nx.read_gexf('data/spanish_ingredients_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients = ingredients_graph.nodes()\n",
    "ingredients.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "ingredients = [i for i in ingredients if i not in spanish_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high altitude adjustment for deep fat frying',\n",
       " \"mrs dash's fiesta lime salt-free seasoning\",\n",
       " 'high altitude adjustment for cookie',\n",
       " 'trappist or monastery-style cheese',\n",
       " 'high altitude baking quick bread',\n",
       " \"i can't believe it's not butter\",\n",
       " 'meat: safe cooking temperature',\n",
       " 'african birdseye chile pepper',\n",
       " 'heirloom weight & measurement',\n",
       " 'trompette de la mort mushroom']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "techniques_graph = nx.read_gexf('data/spanish_techniques_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques = techniques_graph.nodes()\n",
    "techniques.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "techniques = [t for t in techniques if t not in spanish_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thermal immersion circulator',\n",
       " 'extreme-heat stir-fry',\n",
       " 'flash pasteurization',\n",
       " 'amylolytic process',\n",
       " 'biomass briquettes',\n",
       " 'coagulated protein',\n",
       " 'high heat stir fry',\n",
       " 'mongolian barbecue',\n",
       " 'culinary triangle',\n",
       " 'food preservation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 recipes processed.\n",
      "200 recipes processed.\n",
      "300 recipes processed.\n",
      "400 recipes processed.\n",
      "500 recipes processed.\n",
      "600 recipes processed.\n",
      "700 recipes processed.\n",
      "800 recipes processed.\n",
      "900 recipes processed.\n",
      "1000 recipes processed.\n",
      "1100 recipes processed.\n",
      "1200 recipes processed.\n",
      "1300 recipes processed.\n",
      "1400 recipes processed.\n",
      "1500 recipes processed.\n",
      "1600 recipes processed.\n",
      "1700 recipes processed.\n",
      "1800 recipes processed.\n",
      "1900 recipes processed.\n",
      "2000 recipes processed.\n",
      "2100 recipes processed.\n",
      "2200 recipes processed.\n",
      "2300 recipes processed.\n",
      "2400 recipes processed.\n",
      "2500 recipes processed.\n",
      "2600 recipes processed.\n",
      "2700 recipes processed.\n",
      "2800 recipes processed.\n",
      "2900 recipes processed.\n",
      "3000 recipes processed.\n",
      "3100 recipes processed.\n",
      "3200 recipes processed.\n",
      "3300 recipes processed.\n",
      "3400 recipes processed.\n",
      "3500 recipes processed.\n",
      "3600 recipes processed.\n",
      "3700 recipes processed.\n",
      "3800 recipes processed.\n",
      "3900 recipes processed.\n",
      "4000 recipes processed.\n",
      "4100 recipes processed.\n",
      "4200 recipes processed.\n",
      "4300 recipes processed.\n",
      "4400 recipes processed.\n",
      "4500 recipes processed.\n",
      "4600 recipes processed.\n",
      "4700 recipes processed.\n",
      "4800 recipes processed.\n",
      "4900 recipes processed.\n",
      "5000 recipes processed.\n",
      "5100 recipes processed.\n",
      "5200 recipes processed.\n",
      "5300 recipes processed.\n",
      "5400 recipes processed.\n",
      "5500 recipes processed.\n",
      "5600 recipes processed.\n",
      "5700 recipes processed.\n",
      "5800 recipes processed.\n",
      "5900 recipes processed.\n",
      "6000 recipes processed.\n",
      "6100 recipes processed.\n",
      "6200 recipes processed.\n",
      "6300 recipes processed.\n",
      "6400 recipes processed.\n",
      "6500 recipes processed.\n",
      "6600 recipes processed.\n",
      "6700 recipes processed.\n",
      "6800 recipes processed.\n",
      "6900 recipes processed.\n",
      "7000 recipes processed.\n",
      "7100 recipes processed.\n",
      "7200 recipes processed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-be27357c67fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\ncount = 0\\nc=0\\nrows = []\\ntitles=[]\\n# path = 'data/recipes/allrecipes/'\\npath = '/media/antonio/WD1T/datasets recipes/allrecipes/'\\nfor folder_number in sorted(map(int, os.listdir(path))):\\n    folder = str(folder_number)\\n    for filename_number in sorted(map(lambda x: int(x[:-5]), os.listdir(path + folder))):\\n        filename = str(filename_number) + '.html'\\n        with open(path + folder + '/' + filename) as f:\\n            soup = BeautifulSoup(f.read(), 'html.parser')\\n            recipe_info = soup.find('recipe-signup')\\n#             recipe_id = recipe_info['data-id']\\n            recipe_title = recipe_info['data-title']\\n#             recipe_title = recipe_info['data-title'][1:-1].encode('utf_8').decode('unicode_escape')\\n            titles.append(recipe_title)\\n    \\n            c+=1\\n            if c % 100 == 0:\\n                print(c, 'recipes processed.')\\n#             print(recipe_info)\\n#             print(recipe_id)\\n#             print(recipe_title)\\n#             row = {\\n#                 '_id': '',\\n#                 'title': '',\\n#                 'year': 0,\\n#                 'ingredients': set(),\\n#                 'techniques': set(),\\n#             }\\n#             text = ''\\n#             for line in f:\\n#                 line = line.strip()\\n#                 if line.startswith('num'):\\n#                     row['_id'] = line.split('=')[1]\\n#                 elif line.startswith('&titol='):\\n#                     row['title'] = line.split('=')[1]\\n#                 elif line.startswith('&any'):\\n#                     row['year'] = int(line.split('=')[1])\\n#                 elif line.startswith('&ingredientselaboracio') or \\\\\\n#                     line.startswith('&descripcioelaboracio') or \\\\\\n#                     line.startswith('&acabatipresentacio') or \\\\\\n#                     line.startswith('&titolelaboracio'):\\n#                         equals_index = line.index('=')\\n#                         text += line[equals_index + 1:].lower() + ' - '\\n#             i_text = text\\n#             i_text_tokens = nltk.word_tokenize(i_text)\\n#             for ingr in ingredients:\\n#                 ingr_tokens = nltk.word_tokenize(ingr)\\n#                 if (sublist(ingr_tokens, i_text_tokens)):\\n#                     row['ingredients'].add(ingr)\\n#                     i_text = i_text.replace(ingr, '')\\n#                     i_text_tokens = nltk.word_tokenize(i_text)\\n#             row['ingredients'] = list(row['ingredients'])\\n#             t_text = text\\n#             t_text_tokens = nltk.word_tokenize(t_text)\\n#             for tech in techniques:\\n#                 tech_tokens = nltk.word_tokenize(tech)\\n#                 if (sublist(tech_tokens, t_text_tokens)):\\n#                     row['techniques'].add(tech)\\n#                     t_text = t_text.replace(tech, '')\\n#                     t_text_tokens = nltk.word_tokenize(t_text)\\n#             row['techniques'] = list(row['techniques'])\\n#             rows.append(row)\\n#             for ingr in row['ingredients']:\\n#                 ingredients_graph.node[ingr]['count'] += 1\\n#             for tech in row['techniques']:\\n#                 techniques_graph.node[tech]['count'] += 1\\n            \\n#             count += 1\\n#             if count % 100 == 0:\\n#                 db.elbulli.insert_many(rows)\\n#                 rows = []\\n#                 print(count, 'rows inserted')\\n# db.elbulli.insert_many(rows)\\n# rows = []\\n# print(count, 'rows inserted')\\n\\n# CPU times: user 1h 40min 45s, sys: 864 ms, total: 1h 40min 45s\\n# Wall time: 1h 40min 42s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[1;32m/usr/lib/python3.4/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# < + letter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"</\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;31m# XHTML-style empty tag: <span attr=\"value\" />\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/html/parser.py\u001b[0m in \u001b[0;36mhandle_startendtag\u001b[1;34m(self, tag, attrs)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;31m# Overridable -- finish processing of start+end tag: <tag.../>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_startendtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/antonio/virtualenvs/elbulli/lib/python3.4/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, attrs)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mattr_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mattrvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\"\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "count = 0\n",
    "c=0\n",
    "rows = []\n",
    "titles=[]\n",
    "# path = 'data/recipes/allrecipes/'\n",
    "path = '/media/antonio/WD1T/datasets recipes/allrecipes/'\n",
    "for folder_number in sorted(map(int, os.listdir(path))):\n",
    "    folder = str(folder_number)\n",
    "    for filename_number in sorted(map(lambda x: int(x[:-5]), os.listdir(path + folder))):\n",
    "        filename = str(filename_number) + '.html'\n",
    "        with open(path + folder + '/' + filename) as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "            recipe_info = soup.find('recipe-signup')\n",
    "#             recipe_id = recipe_info['data-id']\n",
    "            recipe_title = recipe_info['data-title']\n",
    "#             recipe_title = recipe_info['data-title'][1:-1].encode('utf_8').decode('unicode_escape')\n",
    "            titles.append(recipe_title)\n",
    "    \n",
    "            c+=1\n",
    "            if c % 100 == 0:\n",
    "                print(c, 'recipes processed.')\n",
    "#             print(recipe_info)\n",
    "#             print(recipe_id)\n",
    "#             print(recipe_title)\n",
    "#             row = {\n",
    "#                 '_id': '',\n",
    "#                 'title': '',\n",
    "#                 'year': 0,\n",
    "#                 'ingredients': set(),\n",
    "#                 'techniques': set(),\n",
    "#             }\n",
    "#             text = ''\n",
    "#             for line in f:\n",
    "#                 line = line.strip()\n",
    "#                 if line.startswith('num'):\n",
    "#                     row['_id'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&titol='):\n",
    "#                     row['title'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&any'):\n",
    "#                     row['year'] = int(line.split('=')[1])\n",
    "#                 elif line.startswith('&ingredientselaboracio') or \\\n",
    "#                     line.startswith('&descripcioelaboracio') or \\\n",
    "#                     line.startswith('&acabatipresentacio') or \\\n",
    "#                     line.startswith('&titolelaboracio'):\n",
    "#                         equals_index = line.index('=')\n",
    "#                         text += line[equals_index + 1:].lower() + ' - '\n",
    "#             i_text = text\n",
    "#             i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             for ingr in ingredients:\n",
    "#                 ingr_tokens = nltk.word_tokenize(ingr)\n",
    "#                 if (sublist(ingr_tokens, i_text_tokens)):\n",
    "#                     row['ingredients'].add(ingr)\n",
    "#                     i_text = i_text.replace(ingr, '')\n",
    "#                     i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             row['ingredients'] = list(row['ingredients'])\n",
    "#             t_text = text\n",
    "#             t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             for tech in techniques:\n",
    "#                 tech_tokens = nltk.word_tokenize(tech)\n",
    "#                 if (sublist(tech_tokens, t_text_tokens)):\n",
    "#                     row['techniques'].add(tech)\n",
    "#                     t_text = t_text.replace(tech, '')\n",
    "#                     t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             row['techniques'] = list(row['techniques'])\n",
    "#             rows.append(row)\n",
    "#             for ingr in row['ingredients']:\n",
    "#                 ingredients_graph.node[ingr]['count'] += 1\n",
    "#             for tech in row['techniques']:\n",
    "#                 techniques_graph.node[tech]['count'] += 1\n",
    "            \n",
    "#             count += 1\n",
    "#             if count % 100 == 0:\n",
    "#                 db.elbulli.insert_many(rows)\n",
    "#                 rows = []\n",
    "#                 print(count, 'rows inserted')\n",
    "# db.elbulli.insert_many(rows)\n",
    "# rows = []\n",
    "# print(count, 'rows inserted')\n",
    "\n",
    "# CPU times: user 1h 40min 45s, sys: 864 ms, total: 1h 40min 45s\n",
    "# Wall time: 1h 40min 42s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Counter(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Extra Gingery Bread\" 2\n",
      "\"White Chili I\" 2\n",
      "\"Light Fruitcake\" 2\n",
      "\"Christmas Cookies I\" 2\n",
      "\"Chicken Pot Pie II\" 2\n",
      "\"Pecan Pie Bars I\" 2\n",
      "\"Dad\\u0027s Oyster Dressing\" 2\n",
      "\"Bing Cherry Gelatin Mold\" 2\n",
      "\"Mom\\u0027s Fruitcake\" 2\n",
      "\"Elegant Light Fruit Cake\" 2\n",
      "\"No-Bake Holiday Fruitcake\" 2\n",
      "\"Pecan Pie Bars II\" 3\n",
      "\"Mincemeat Cake\" 2\n",
      "\"Crushed Pineapple Fruitcake\" 2\n",
      "\"Peanut Butter Pie\" 2\n",
      "\"Brown Sugar Sauce\" 2\n",
      "\"Pasta e Fagioli I\" 2\n",
      "\"Grilled Goose with Prune Stuffing and Gravy\" 2\n",
      "\"Cherry Almond Cake\" 2\n",
      "\"Whipped Shortbread Cookies\" 2\n",
      "\"Apple and Onion Dressing\" 2\n",
      "\"Baby Carrots And Brussels Sprouts Glazed With Brown Sugar and Pepper\" 2\n",
      "\"Serious Herb Cheese Spread\" 2\n",
      "\"Pumpkin Crunch Cake\" 2\n",
      "\"Chocolate Caramel Candy\" 2\n",
      "\"Cranberry Chutney II\" 2\n",
      "\"Cocoa Apple Cake\" 2\n",
      "\"Baked Whole Pumpkin\" 2\n",
      "\"Sweet Potato Casserole IV\" 2\n",
      "\"Tarragon Stuffing\" 2\n",
      "\"Tony\\u0027s Summer Pasta\" 2\n",
      "\"Pumpkin Soup\" 2\n",
      "\"Aunt Wanda\\u0027s Turkey Carcass Soup\" 2\n",
      "\"Easy Light Fruitcake\" 2\n",
      "\"Three Bean Salad\" 2\n",
      "\"Stuffed Celery\" 2\n",
      "\"Screaming Potatoes\" 2\n",
      "\"Yorkshire Pudding\" 2\n",
      "\"Cranberry Waldorf\" 2\n",
      "\"Mom\\u0027s Great Green Beans\" 2\n",
      "\"Eggnog Cookies I\" 2\n",
      "\"Lucy\\u0027s Carrot Pudding\" 2\n",
      "\"Johnsonville(R) Three Cheese Italian Style Chicken Sausage Skillet Pizza\" 2\n",
      "\"Nutty Wild Rice Salad with Kiwifruit and Red Grapes\" 2\n",
      "\"Vanilla Bavarian Cream Pie\" 2\n",
      "\"Orange and Onion Salad\" 2\n",
      "\"Cranberry Salad III\" 2\n",
      "\"Plum Bread\" 2\n",
      "\"Corn Pudding IV\" 2\n",
      "\"Spicy Persimmon Chutney\" 2\n",
      "\"Blueberry Muffins II\" 2\n",
      "\"Cranberry Salad II\" 2\n",
      "\"Buttery Pan Rolls\" 2\n",
      "\"Heavenly Chipped Chocolate and Hazelnut Cheesecake\" 2\n",
      "\"Squash-Carrot Casserole\" 2\n",
      "\"Pumpkin Roll II\" 2\n",
      "\"Christmas Cake\" 2\n",
      "\"Jam Muffins\" 2\n",
      "\"Super Moist Pumpkin Bread\" 2\n",
      "\"Nut Rolls\" 2\n",
      "\"Chewy Noels\" 2\n",
      "\"Tuna Noodle Casserole I\" 2\n",
      "\"Cranberry Sauce with Raspberry Vinegar\" 2\n",
      "\"Popcorn Cake I\" 2\n",
      "\"Pumpkin Cheese Pie\" 2\n",
      "\"Christmas Wreath Cake\" 2\n",
      "\"Dee\\u0027s Date and Nut Bread\" 2\n",
      "\"Baked Sweet Potato Sticks\" 2\n",
      "\"Sweet Potato Pecan Pie\" 2\n",
      "\"Chocolate Plum Pudding Cake\" 2\n",
      "\"Cranberry, Sausage and Apple Stuffing\" 2\n",
      "\"Maple Roast Turkey and Gravy\" 2\n",
      "\"French Fruitcake\" 2\n",
      "\"Pumpkin Bars I\" 2\n",
      "\"Tuna Noodle Casserole II\" 2\n",
      "\"Double Layer Pumpkin Cheesecake\" 2\n",
      "\"Sweet Potato Casserole III\" 2\n",
      "\"Pecan Cheesecake\" 2\n",
      "\"Make-Ahead Mashed Potatoes\" 2\n",
      "\"Bacon Turnip Mash\" 2\n",
      "\"Roast Turkey With Tasty Chestnut Stuffing\" 2\n",
      "\"Chess Cake\" 2\n",
      "\"Peanut Butter Fudge I\" 2\n",
      "\"Pumpkin Bread I\" 2\n",
      "\"Baked Fennel with Gorgonzola\" 2\n",
      "\"Feta Cheese Foldovers\" 2\n",
      "\"Baked Ziti with Turkey Meatballs\" 2\n",
      "\"Whipping Cream Pound Cake\" 2\n",
      "\"Pecan Tassies\" 2\n",
      "\"Chicken Pot Pie I\" 2\n",
      "\"Hearty Turkey Soup with Parsley Dumplings\" 2\n",
      "\"Pumpkin Pecan Cheesecake\" 2\n",
      "\"Butterhorn Rolls\" 2\n",
      "\"Rich Dark Fruitcake\" 2\n",
      "\"Pumpkin Roll I\" 2\n",
      "\"Pumpkin Spice Ring\" 2\n",
      "\"Baklava\" 2\n",
      "\"Peanut Brittle\" 2\n",
      "\"Cranberry Muffins\" 2\n",
      "\"Molasses Sugar Cookies\" 2\n",
      "\"Poultry Seasoning\" 2\n",
      "\"Sweet Potato Casserole I\" 2\n",
      "\"Bread Pudding I\" 3\n",
      "\"Cream Cheese Frosting I\" 2\n",
      "\"Artichoke, Mushroom and Parma Ham Tart\" 2\n",
      "\"Mussels Mariniere\" 2\n",
      "\"Cranberry Apple Gelatin Mold\" 2\n",
      "\"Rutabaga Casserole\" 2\n",
      "\"Carrot Fruit Ring\" 2\n",
      "\"Dad\\u0027s Pumpkin Chiffon Pie\" 2\n",
      "\"Christmas Wreaths\" 2\n",
      "\"Dressing Patties\" 2\n",
      "\"Hawaiian Fruit Crumble\" 2\n",
      "\"English Trifle\" 2\n",
      "\"Gourmet Pumpkin Pie\" 2\n",
      "\"Pumpkin Biscuits\" 2\n",
      "\"Pecan Pie\" 2\n",
      "\"Turkey Tenderloins\" 2\n",
      "\"German Christmas Gingerbread\" 2\n",
      "\"Peanut Butter Pie III\" 2\n",
      "\"Pumpkin Mousse\" 2\n",
      "\"Pumpkin Cheesecake I\" 2\n",
      "\"Ma Lipo\\u0027s Apricot-Glazed Turkey with Roasted Onion and Shallot Gravy\" 2\n",
      "\"Sara\\u0027s Pumpkin Pie\" 2\n",
      "\"Scotch Eggs\" 2\n",
      "\"Cranberry Nut Bread I\" 2\n",
      "\"Nutmeg Mushrooms\" 2\n",
      "\"Orange Glazed Sweet Potatoes\" 2\n",
      "\"Minnehaha Cake\" 2\n",
      "\"Pumpkin Cookies I\" 2\n",
      "\"Chocolate Icing\" 2\n",
      "\"Gingerbread Men\" 2\n",
      "\"Chicken Noodle Casserole I\" 2\n",
      "\"Baked Miniature Pumpkins\" 2\n",
      "\"Old-Fashioned Scalloped Corn\" 2\n",
      "\"Oranged Cranberry Sauce\" 2\n",
      "\"Cranberry Relish I\" 2\n",
      "\"Melt In Your Mouth Pie\" 2\n",
      "\"Cranberry Swirl Coffee Cake\" 2\n",
      "\"No Bake Fruitcake\" 2\n",
      "\"Chocolate Pecan Pie I\" 2\n",
      "\"Blue Cheese, Port, and Walnut Spread\" 2\n",
      "\"Mocha Walnut Cookies\" 2\n",
      "\"Chicken and Dumplings I\" 2\n",
      "\"Oyster Stuffing\" 2\n",
      "\"Brandied Candied Sweet Potatoes\" 2\n",
      "\"Amber\\u0027s Super Stuffing\" 2\n",
      "\"Sweet Potato Casserole V\" 2\n",
      "\"Popcorn Cake II\" 2\n",
      "\"Wild Mushroom Stuffing\" 2\n",
      "\"Butter Frosting\" 2\n",
      "\"Green Turkey and Cheese\" 2\n",
      "\"Aunt Carol\\u0027s Apple Pie\" 2\n",
      "\"Boiled Fruitcake\" 2\n",
      "\"Bread Pudding II\" 2\n",
      "\"Sweet Potato Casserole II\" 2\n",
      "\"Dutch Cookies\" 2\n",
      "\"Holiday Refrigerator Cake\" 2\n",
      "\"Butternut Squash with Onions and Pecans\" 2\n",
      "\"Stuffed Turkey Legs\" 2\n",
      "\"Cranberry Stuffed Turkey Breasts\" 2\n",
      "\"Sausage Stuffing\" 2\n",
      "\"Corn Pudding III\" 2\n",
      "\"Pumpkin Casserole\" 2\n",
      "\"Great Grandma\\u0027s Bread Stuffing\" 2\n",
      "\"Orange Muffins\" 2\n",
      "\"Pumpkin Bread II\" 2\n",
      "\"Cranberry Relish II\" 2\n",
      "\"Cajun Chicken Pasta\" 2\n",
      "\"Slow Cooker Stuffing\" 2\n",
      "\"Corn Pudding II\" 2\n",
      "\"Corn Pudding I\" 2\n",
      "\"Mom\\u0027s Traditional Creamed Onions\" 2\n",
      "\"Pumpkin Cheesecake II\" 2\n",
      "\"Savory Turkey Gravy\" 2\n",
      "\"Pear Conserve with Cherries and Hazelnuts\" 2\n",
      "\"Eggnog and Cranberry Salad\" 2\n",
      "\"Green Beans With Walnuts\" 2\n",
      "\"Smashed Sweet Potatoes\" 2\n",
      "\"Awesome Broccoli-Cheese Casserole\" 2\n",
      "\"Mincemeat and Pumpkin Layer Pie\" 2\n",
      "\"Peanut Pie\" 2\n",
      "\"Fire and Ice Pasta\" 2\n",
      "\"Rosemary Roasted Turkey\" 2\n",
      "\"Sweet Potato Fluff\" 2\n",
      "\"Cranberry Chutney I\" 2\n",
      "\"Unbaked Fruit Cake\" 2\n",
      "\"Moore\\u0027s Cranberry Gelatin Salad\" 2\n",
      "\"Mom\\u0027s Brazil Nut Fruitcake\" 2\n",
      "\"Butter Tarts\" 2\n",
      "\"Crab Bisque\" 2\n",
      "\"Chestnut Soup\" 2\n",
      "\"Chocolate Chip Pie II\" 2\n",
      "\"Joey\\u0027s Bread Pudding\" 2\n",
      "\"Festive Onions\" 2\n",
      "\"Ibby\\u0027s Pumpkin Mushroom Stuffing\" 2\n",
      "\"Sugarless Pumpkin Pie\" 2\n",
      "\"French Tourtiere\" 2\n",
      "\"Chess Pie\" 2\n",
      "\"Michelle\\u0027s Famous Washed Cranberry Sauce\" 2\n",
      "\"Creamed Onions and Sage\" 2\n",
      "\"Fruit Cocktail Cake\" 2\n",
      "\"Sugarless Fruitcake\" 2\n",
      "\"Seafood Lasagna I\" 2\n",
      "\"Cherry Salad\" 2\n",
      "\"Cream Cheese Corn\" 2\n",
      "\"Seven Minute Frosting I\" 2\n",
      "\"Cranberry Salad I\" 2\n",
      "\"Christmas Cherry Cake\" 2\n",
      "\"Peanut Butter Fudge II\" 2\n",
      "\"Pumpkin Cookies II\" 2\n",
      "\"Harvest Pumpkin Soup\" 2\n",
      "\"Yeast Hot Rolls\" 2\n",
      "\"Chocolate Rum Cake\" 2\n",
      "\"Cranberry Conserve\" 2\n",
      "\"Thanksgiving Meatloaf\" 2\n",
      "\"Delmonico Potatoes\" 2\n",
      "\"Blueberry Muffins I\" 2\n",
      "\"Cranberry Cherry Pie\" 2\n",
      "\"Christmas Fruitcake\" 2\n",
      "\"Vegetarian Stuffing\" 2\n",
      "\"Fruitcake Without Citron\" 2\n",
      "\"Frosted Pecan Bites\" 2\n",
      "\"Fruitcake\" 2\n",
      "\"Dee\\u0027s Hot Milk Sponge Cake\" 2\n",
      "\"Creole Cornbread Stuffing\" 2\n",
      "\"Baked Sweet Potatoes with Ginger and Honey\" 2\n",
      "\"Winter Fruit Salad with Lemon Poppyseed Dressing\" 2\n",
      "\"Pumpkin Fudge\" 2\n",
      "\"Cream Cheese Christmas Cookies\" 2\n",
      "\"Pumpkin Pie Cake I\" 2\n",
      "\"Valerie\\u0027s Cherry Choco-Chip Cake\" 2\n",
      "\"Southern Candied Sweet Potatoes\" 2\n",
      "\"Lemon Cream Cheese Frosting\" 2\n",
      "\"Patty\\u0027s Mashed Turnips\" 2\n",
      "\"Green Bean Casserole II\" 2\n",
      "\"Carrot Bars\" 2\n",
      "\"Favorite Old Fashioned Gingerbread\" 2\n",
      "\"Three Cranberry Relish\" 2\n",
      "\"Harvest Rice Dish\" 2\n",
      "\"Green Bean Casserole I\" 2\n",
      "\"Candied Sweet Potatoes\" 2\n",
      "\"Icelandic Christmas Cake\" 2\n",
      "\"Insalata Cotta e Cruda\" 2\n",
      "\"Romaine with Garlic Lemon Anchovy Dressing\" 2\n",
      "\"Butter Tart Muffins\" 2\n",
      "\"Pumpkin Pie I\" 2\n",
      "\"Sweet Potato Balls\" 2\n",
      "\"Red Pepper and Corn Relish\" 2\n",
      "\"Corn Souffle\" 2\n",
      "\"Cranberry-Black Cherry Gelatin Salad\" 2\n",
      "\"Apricot Fruitcake\" 2\n",
      "\"Red Cabbage With Apricots And Balsamic Vinegar\" 2\n",
      "\"Turkey \\u0027n Stuffing Bake\" 2\n",
      "\"Mafioso Chocolate Cake\" 2\n",
      "\"Squash Casserole I\" 2\n",
      "\"Cow Pies\" 2\n",
      "\"Potato and Shiitake Mushroom Gratin\" 2\n",
      "\"Lilley Mashed Potato Casserole\" 2\n",
      "\"Raisin Cheesecake\" 2\n",
      "\"Homestyle Turkey, the Michigander Way\" 2\n",
      "\"Roasted Root Vegetables With Apple Juice\" 2\n",
      "\"Herman Coffee Cake\" 2\n",
      "\"Walnut Pumpkin Pie\" 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for k in c:\n",
    "    if c[k] > 1:\n",
    "        print(k, c[k])\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<recipe-signup data-id=\"6901\" data-imageurl=\"'http://images.media-allrecipes.com/userphotos/250x250/519596.jpg'\" data-title='\"Zucchini Pineapple Loaf\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "6901\n",
      "\"Zucchini Pineapple Loaf\"\n",
      "<recipe-signup data-id=\"6902\" data-imageurl=\"'http://images.media-allrecipes.com/userphotos/250x250/989336.jpg'\" data-title='\"Indian Naan I\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "6902\n",
      "\"Indian Naan I\"\n",
      "<recipe-signup data-id=\"6903\" data-imageurl=\"'http://images.media-allrecipes.com/userphotos/250x250/343742.jpg'\" data-title='\"Grandma\\u0027s English Muffin Bread\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "6903\n",
      "\"Grandma\\u0027s English Muffin Bread\"\n",
      "<recipe-signup data-id=\"6904\" data-imageurl=\"'http://images.media-allrecipes.com/userphotos/250x250/1834701.jpg'\" data-title='\"Chocolate Filled Muffins\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "6904\n",
      "\"Chocolate Filled Muffins\"\n",
      "<recipe-signup data-id=\"6905\" data-imageurl=\"'http://images.media-allrecipes.com/userphotos/250x250/124051.jpg'\" data-title='\"Apple Scones\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "6905\n",
      "\"Apple Scones\"\n",
      "<recipe-signup data-id=\"246279\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"White Chocolate Fondue\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246279\n",
      "\"White Chocolate Fondue\"\n",
      "<recipe-signup data-id=\"246245\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Jan\\u0027s Savory Breakfast Sausage Patties (Paleo)\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246245\n",
      "\"Jan\\u0027s Savory Breakfast Sausage Patties (Paleo)\"\n",
      "<recipe-signup data-id=\"246247\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Quick and Easy Kimchi Salad\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246247\n",
      "\"Quick and Easy Kimchi Salad\"\n",
      "<recipe-signup data-id=\"246250\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Kima\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246250\n",
      "\"Kima\"\n",
      "<recipe-signup data-id=\"246255\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Hot Baked Reuben Dip\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246255\n",
      "\"Hot Baked Reuben Dip\"\n",
      "<recipe-signup data-id=\"246256\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Bacon Jalapeno Popper Puffs\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246256\n",
      "\"Bacon Jalapeno Popper Puffs\"\n",
      "<recipe-signup data-id=\"246274\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Spatchcocked Chicken\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246274\n",
      "\"Spatchcocked Chicken\"\n",
      "<recipe-signup data-id=\"246275\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Fresh Butter\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246275\n",
      "\"Fresh Butter\"\n",
      "<recipe-signup data-id=\"246276\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Rosemary-Ginger Cocktail\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246276\n",
      "\"Rosemary-Ginger Cocktail\"\n",
      "<recipe-signup data-id=\"246277\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"Tres Leches Cake\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246277\n",
      "\"Tres Leches Cake\"\n",
      "<recipe-signup data-id=\"246279\" data-imageurl=\"'http://images.media-allrecipes.com/global/recipes/nophoto/nopicture-250x250.png'\" data-title='\"White Chocolate Fondue\"' data-type=\"'Recipe'\">\n",
      "</recipe-signup>\n",
      "246279\n",
      "\"White Chocolate Fondue\"\n",
      "CPU times: user 2.86 s, sys: 20 ms, total: 2.88 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "count = 0\n",
    "rows = []\n",
    "\n",
    "path = 'data/recipes/allrecipes/'\n",
    "for folder_number in sorted(map(int, os.listdir(path))):\n",
    "    folder = str(folder_number)\n",
    "    for filename_number in sorted(map(lambda x: int(x[:-5]), os.listdir(path + folder))):\n",
    "        filename = str(filename_number) + '.html'\n",
    "        with open(path + folder + '/' + filename) as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "            recipe_info = soup.find('recipe-signup')\n",
    "            recipe_id = recipe_info['data-id']\n",
    "            recipe_title = recipe_info['data-title']\n",
    "#             recipe_title = recipe_info['data-title'][1:-1].encode('utf_8').decode('unicode_escape')\n",
    "            \n",
    "            print(recipe_info)\n",
    "            print(recipe_id)\n",
    "            print(recipe_title)\n",
    "#             row = {\n",
    "#                 '_id': '',\n",
    "#                 'title': '',\n",
    "#                 'year': 0,\n",
    "#                 'ingredients': set(),\n",
    "#                 'techniques': set(),\n",
    "#             }\n",
    "#             text = ''\n",
    "#             for line in f:\n",
    "#                 line = line.strip()\n",
    "#                 if line.startswith('num'):\n",
    "#                     row['_id'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&titol='):\n",
    "#                     row['title'] = line.split('=')[1]\n",
    "#                 elif line.startswith('&any'):\n",
    "#                     row['year'] = int(line.split('=')[1])\n",
    "#                 elif line.startswith('&ingredientselaboracio') or \\\n",
    "#                     line.startswith('&descripcioelaboracio') or \\\n",
    "#                     line.startswith('&acabatipresentacio') or \\\n",
    "#                     line.startswith('&titolelaboracio'):\n",
    "#                         equals_index = line.index('=')\n",
    "#                         text += line[equals_index + 1:].lower() + ' - '\n",
    "#             i_text = text\n",
    "#             i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             for ingr in ingredients:\n",
    "#                 ingr_tokens = nltk.word_tokenize(ingr)\n",
    "#                 if (sublist(ingr_tokens, i_text_tokens)):\n",
    "#                     row['ingredients'].add(ingr)\n",
    "#                     i_text = i_text.replace(ingr, '')\n",
    "#                     i_text_tokens = nltk.word_tokenize(i_text)\n",
    "#             row['ingredients'] = list(row['ingredients'])\n",
    "#             t_text = text\n",
    "#             t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             for tech in techniques:\n",
    "#                 tech_tokens = nltk.word_tokenize(tech)\n",
    "#                 if (sublist(tech_tokens, t_text_tokens)):\n",
    "#                     row['techniques'].add(tech)\n",
    "#                     t_text = t_text.replace(tech, '')\n",
    "#                     t_text_tokens = nltk.word_tokenize(t_text)\n",
    "#             row['techniques'] = list(row['techniques'])\n",
    "#             rows.append(row)\n",
    "#             for ingr in row['ingredients']:\n",
    "#                 ingredients_graph.node[ingr]['count'] += 1\n",
    "#             for tech in row['techniques']:\n",
    "#                 techniques_graph.node[tech]['count'] += 1\n",
    "            \n",
    "#             count += 1\n",
    "#             if count % 100 == 0:\n",
    "#                 db.elbulli.insert_many(rows)\n",
    "#                 rows = []\n",
    "#                 print(count, 'rows inserted')\n",
    "# db.elbulli.insert_many(rows)\n",
    "# rows = []\n",
    "# print(count, 'rows inserted')\n",
    "\n",
    "# CPU times: user 1h 40min 45s, sys: 864 ms, total: 1h 40min 45s\n",
    "# Wall time: 1h 40min 42s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(map(int, os.listdir(path)))[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'unicodeescape' codec can't decode byte 0x5c in position 30: \\ at end of string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-edc7900a2a17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecipe_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data-title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf_8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'unicodeescape' codec can't decode byte 0x5c in position 30: \\ at end of string"
     ]
    }
   ],
   "source": [
    "recipe_info['data-title'][1:-2].encode('utf_8').decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/ingredients/allrecipes_ingr_ids_111.csv', 'w') as f1,\\\n",
    "     open('data/techniques/allrecipes_techniques_111.csv', 'w') as f2,\\\n",
    "     open('data/ingredient_technique_log_111.txt', 'w') as log:\n",
    "    writer1 = csv.writer(\n",
    "        f1,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "    writer2 = csv.writer(\n",
    "        f2,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "    writer3 = csv.writer(\n",
    "        log,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "    path = '/media/antonio/WD1T/datasets allrecipes and epicurious/allrecipes/'\n",
    "#     path = 'data/allrecipes/'\n",
    "    for folder_number in sorted(map(int, os.listdir(path)))[111:]:\n",
    "        folder_name = str(folder_number)\n",
    "        folder_path = path + folder_name\n",
    "        for file_name in sorted(map(lambda x: int(x[:-5]), os.listdir(folder_path))):\n",
    "            file_name = str(file_name) + '.html'\n",
    "            file_path = folder_path + '/' + file_name\n",
    "            with open(file_path) as f:\n",
    "                soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "                recipe_info = soup.find('recipe-signup')\n",
    "                recipe_id = recipe_info['data-id']\n",
    "                recipe_title = recipe_info['data-title'][1:-1].encode('utf_8').decode('unicode_escape')\n",
    "                info_row = [recipe_id, recipe_title]\n",
    "                \n",
    "                ingredient_ids = set()\n",
    "                ingredient_amounts = soup.select('section.recipe-ingredients span[itemprop=ingredients]')\n",
    "                for ingredient_amount in ingredient_amounts:\n",
    "                    ingredient_id = ingredient_amount['data-id']\n",
    "                    content = ingredient_amount.text.strip()\n",
    "                    if content:\n",
    "                        tokens = nltk.word_tokenize(content)\n",
    "                        singularized = ' '.join(map(singularize, tokens))\n",
    "                        found_ingr = False\n",
    "                        for ingredient in ingredients:\n",
    "                            if ingredient in singularized:\n",
    "                                found_ingr = True\n",
    "                                ingredient_ids.add(ingredient_id)\n",
    "                                if ingr_id_graph.add_edge(ingredient_id, ingredient):\n",
    "                                    ingr_id_graph[ingredient_id][ingredient]['weight'] += 1\n",
    "                                else:\n",
    "                                    ingr_id_graph.add_edge(ingredient_id, ingredient, weight=1)\n",
    "                        if not found_ingr:\n",
    "                            writer3.writerow(['INGREDIENT', file_path, singularized])\n",
    "                ingredient_row = info_row + list(ingredient_ids)\n",
    "                writer1.writerow(ingredient_row)\n",
    "                \n",
    "                technique_names = set()\n",
    "                instructions = soup.select('section.recipe-directions span.recipe-directions__list--item')\n",
    "                for instruction in instructions:\n",
    "                    content = instruction.text.strip()\n",
    "                    if content:\n",
    "                        tokens = nltk.word_tokenize(content)\n",
    "                        infinitived = ' '.join(map(infinitive, tokens))\n",
    "                        found_tech = False\n",
    "                        for technique in techniques:\n",
    "                            if technique in infinitived:\n",
    "                                found_tech = True\n",
    "                                technique_names.add(technique)\n",
    "                        if not found_tech:\n",
    "                            writer3.writerow(['TECHNIQUE', file_path, infinitived])\n",
    "                technique_row = info_row + list(technique_names)\n",
    "                writer2.writerow(technique_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 recipes processed.\n",
      "20000 recipes processed.\n",
      "30000 recipes processed.\n",
      "40000 recipes processed.\n",
      "50000 recipes processed.\n",
      "60000 recipes processed.\n",
      "70000 recipes processed.\n",
      "80000 recipes processed.\n",
      "90000 recipes processed.\n",
      "100000 recipes processed.\n",
      "110000 recipes processed.\n",
      "120000 recipes processed.\n",
      "130000 recipes processed.\n",
      "140000 recipes processed.\n",
      "150000 recipes processed.\n",
      "160000 recipes processed.\n",
      "170000 recipes processed.\n",
      "180000 recipes processed.\n",
      "190000 recipes processed.\n",
      "200000 recipes processed.\n",
      "210000 recipes processed.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ingredients_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-be8d33ead12a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recipes processed.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# nx.write_gexf(ingr_id_graph, 'data/ingredients/ingr_id_graph.gexf')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mingredients_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ingredients_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# ingr_id_graph = nx.Graph()\n",
    "path = '/media/antonio/WD1T/datasets allrecipes and epicurious/allrecipes/'\n",
    "#     path = 'data/allrecipes/'\n",
    "c=0\n",
    "ingredient_ids = set()\n",
    "for folder_number in sorted(map(int, os.listdir(path))):\n",
    "    folder_name = str(folder_number)\n",
    "    folder_path = path + folder_name\n",
    "    for file_name in sorted(map(lambda x: int(x[:-5]), os.listdir(folder_path))):\n",
    "        file_name = str(file_name) + '.html'\n",
    "        file_path = folder_path + '/' + file_name\n",
    "        with open(file_path) as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#             recipe_info = soup.find('recipe-signup')\n",
    "#             recipe_id = recipe_info['data-id']\n",
    "#             recipe_title = recipe_info['data-title'][1:-1].encode('utf_8').decode('unicode_escape')\n",
    "#             info_row = [recipe_id, recipe_title]\n",
    "\n",
    "            ingredient_amounts = soup.select('section.recipe-ingredients span[itemprop=ingredients]')\n",
    "            for ingredient_amount in ingredient_amounts:\n",
    "                ingredient_id = ingredient_amount['data-id']\n",
    "                content = ingredient_amount.text.strip()\n",
    "                if content:\n",
    "                    tokens = nltk.word_tokenize(content)\n",
    "                    singularized = ' '.join(map(singularize, tokens))\n",
    "#                     found_ingr = False\n",
    "                    for ingredient in ingredients:\n",
    "                        if ingredient in singularized:\n",
    "#                             found_ingr = True\n",
    "                            ingredient_ids.add(ingredient_id)\n",
    "#                             if ingr_id_graph.has_edge(ingredient_id, ingredient):\n",
    "#                                 ingr_id_graph[ingredient_id][ingredient]['weight'] += 1\n",
    "#                             else:\n",
    "#                                 ingr_id_graph.add_edge(ingredient_id, ingredient, weight=1)\n",
    "#                     if not found_ingr:\n",
    "#                         writer3.writerow(['INGREDIENT', file_path, singularized])\n",
    "#             ingredient_row = info_row + list(ingredient_ids)\n",
    "#             writer1.writerow(ingredient_row)\n",
    "            c+=1\n",
    "            if c % 10000 == 0:\n",
    "                print(c, 'recipes processed.')\n",
    "# nx.write_gexf(ingr_id_graph, 'data/ingredients/ingr_id_graph.gexf')\n",
    "print(len(ingredients_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10860\n"
     ]
    }
   ],
   "source": [
    "print(len(ingredient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Store ingredient_ids on a pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12242"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingr_id_graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingr_id_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8263"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for n in ingr_id_graph.nodes(data=False):\n",
    "#     ns = ingr_id_graph.neighbors(n)\n",
    "#     for ne in ns:\n",
    "    anyy=False\n",
    "    for ne in ingr_id_graph[n]:\n",
    "        if ingr_id_graph[n][ne]['weight'] > 1:\n",
    "#             print(n)\n",
    "#             print(ingr_id_graph[n])\n",
    "#             print()\n",
    "            anyy=True\n",
    "            break\n",
    "    if anyy:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss='123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10860"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "nums=set()\n",
    "for n in ingr_id_graph.nodes(data=False):\n",
    "#     ns = ingr_id_graph.neighbors(n)\n",
    "#     for ne in ns:\n",
    "    \n",
    "    if n.isdigit():\n",
    "        c+=1\n",
    "        nums.add(n)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10860"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nx.write_gexf(ingr_id_graph, 'data/ingredients/ingr_id_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('data/allrecipes/6000/6903.html') as f:\n",
    "#     soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#     info = soup.find('recipe-signup')\n",
    "#     print(info['data-id'])\n",
    "#     print(info['data-title'])\n",
    "#     qq=info['data-title']\n",
    "#     info_row = [info['data-id'], info['data-title']]\n",
    "#     technique_names = []\n",
    "#     instructions = soup.select('section.recipe-directions span.recipe-directions__list--item')\n",
    "#     for instruction in instructions:\n",
    "#         infinitived = ' '.join(map(infinitive, instruction.string.strip().split()))\n",
    "#         for technique in techniques:\n",
    "#             if technique in infinitived:\n",
    "#                 technique_names.append(technique)\n",
    "#     technique_row = info_row + technique_names\n",
    "#     print(technique_row)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# las tecnicas no tienen pq ser solo verbos - pueden ser sustantivos, por ejemplo, bbq, fondue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for folder_name in os.listdir('data/allrecipes/'):\n",
    "#     folder_path = 'data/allrecipes/' + folder_name\n",
    "#     for file_name in os.listdir(folder_path):\n",
    "#         file_path = folder_path + '/' + file_name\n",
    "#         with open(file_path) as f:\n",
    "#             soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#             info = soup.find('recipe-signup')\n",
    "#             print(info['data-id'])\n",
    "#             print(info['data-title'])\n",
    "#             ingredients = soup.select('span[itemprop=ingredients]')\n",
    "#             for ingredient in ingredients:\n",
    "#                 print(ingredient.string.strip())\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
